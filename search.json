[{"title":"How to use hexo","url":"/2022/02/10/How-to-use-hexo/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start·\nCreate a new post·\n$ hexo new &quot;My New Post&quot;\nMore info: Writing\nRun server·\n$ hexo server\nMore info: Server\nGenerate static files·\n$ hexo generate\nMore info: Generating\nDeploy to remote sites·\n$ hexo deploy\nMore info: Deployment\n"},{"title":"It's my Hello,World!","url":"/2023/11/17/My-Hello-World/","content":"这是我的第一篇博客，作为“程序员”的我，理应叫他&quot;Hello,World!&quot;\n(其实我不太喜欢“程序员”这个称呼，因为总感觉它带着一些刻板印象在里面。)\nIntroduce myself·\n第一篇也也不知道说些什么，就随便唠叨唠叨了。\n那就先介绍一下自己。个人目前是在武汉做LLVM编译器开发，目前主要的工作是做编译优化。当初因为很喜欢计算机底层知识，所以选择了这个方向。可能由于国内做编译器的很少，所以同行竞争压力比较小，加上我们的老板和总监之前都是常年在国外创业和工作，所以工作氛围很轻松，而且工作时间是真的弹性965。\n但是工作压力还是有的，主要是因为编译器软件过于庞大，计算机底层知识牵涉过多，所以有时候举步维艰。所以这也是我花费周末时间搭这个博客的一点原因，想借助这个博客来记录自己的学习。当然其实更多的是兴趣使然，不然我是不可能凌晨熬夜还在看这个前端代码的。\n工作五个月，从最开始接触linux指令，跑测试，整理数据，到开始做code size相关的优化（主要是outline相关），现在由于公司要用picolibc库开发，所以最近都在和picolibc打交道，所以也接触到了很多链接器相关的东西。我的工作其实说起来很无聊，就是测试，对比，阅读LLVM源码，在源码基础上做优化，但我很喜欢我的工作，可能本身对计算机底层的兴趣使我不会那么厌烦。工作中有很多很难的东西，比如要去阅读上千上万行的源码，虽然LLVM已经有十多年的时间了，但是能参考的资料真的不是很多，而且几乎没有中文，只能硬着头皮去看英文文档。遇到特别难的东西，其实真的也会很暴躁。😦\n结果就是，在技术方面，我真的成长了许多，但现在仍然还是个菜鸡。\n\nAbout my life·\n我也很喜欢我的生活，也有很多想做的事情。\n曾经刚来武汉的一段时间，我非常暴躁，大概是因为一个人来到一座城市，没有亲人朋友的孤独感。每天打开房门，面对的就是一个黑咕隆咚的地方，好像要被吞进去，打开灯，当然仍旧是走之前的老样子，没人陪伴孤独的样子。\n现在倒是好多了，或许是因为我放下了一些执念？又或许是我看了一些书？who knows，总之真的在变好了，无论是面对的生活，还是在情绪上。希望以后会越来越好。\nHappy ending·\n总之，搭这个博客的目的，主要就是为了记录自己的生活和学习。这里也算是我自己的小天地了。\n","tags":["Hello,Wolrd!"]},{"title":"In-Order Pipeline and Pipeline Stalls","url":"/2025/05/16/Scheduling-Models-1/","content":"Framework·\n\nUnderstanding In-Order Pipelines and Pipeline Stalls\nWhat We Need in a Scheduling Model: GCC and LLVM Perspectives\nWriting a Scheduling Model from Scratch\nTuning Your Scheduling Model for Better Performance\nRecommended Readings on Out-of-Order Execution and Scheduling\n\nExtended in-order pipeline·\nExtended EX stage pipeline·\n\n我不想在这里讨论基本的五级顺序流水线概念，你可以在任何一本介绍计算机体系结构的书上找到相关的内容，所以我会假设你已经了解基本的顺序流水线知识、流水线冒险（结构冒险、数据冒险、控制冒险）、数据前推，如果你对提到的任何关键词有疑问，请先补充相关的知识 😉\n\nflowchart LR\n    IF[IF]\n    ID[ID]\n    EX[EX]\n    MEM[MEM]\n    WB[WB]\n\n    IF --&gt; ID\n    ID --&gt; EX\n    EX --&gt; MEM\n    MEM --&gt; WB\n如上图，基本的五级流水线（取指，译码，执行，访存，写回）由于做了简化，并没有暴露其中的细节。从图中看起来所有的执行单元被抽象成一个 EX stage，而真实的 CPU 流水线不仅要处理基本的整数运算，还需要处理浮点运算以及它们各自的加减乘除，所以一个完整的 EX stage 至少会包括 ALU 单元运算，乘法除法器运算单元，浮点加减运算单元，浮点乘除运算单元。\n假设我们有一个可以处理各种整数运算，浮点加减乘除运算的流水线，从黑盒子的角度来看，它可能长成下图这个样子。\n\nflowchart LR\n    IF[IF]\n    ID[ID]\n    INT_OP[Integer Unit]\n    FP_ADD[FP Add/Sub]\n    FP_MUL[FP Mul]\n    FP_DIV[FP DIV]\n    MUL[MUL/DIV]\n    MEM[MEM]\n    WB[WB]\n\n    IF --&gt;| | ID\n    ID --&gt;| | MUL\n    ID --&gt;| | FP_DIV\n    ID --&gt;| | INT_OP\n    ID --&gt;| | FP_ADD\n    ID --&gt;| | FP_MUL\n    MUL --&gt;| | MEM\n    INT_OP --&gt;| | MEM\n    FP_ADD --&gt;| | MEM\n    FP_MUL --&gt;| | MEM\n    FP_DIV --&gt;| | MEM\n    MEM --&gt;| | WB\n\n不同硬件实现不同，可能有些流水线会把一些功能单元做合并或拆分，比如将 MUL 和 DIV 分开，分别负责整数乘法和除法。\n\n假设我们现在有这样一段汇编代码，\nadd    a0, a1  --&gt; integer unitmul    a2, a3  --&gt; mul/divfp_mul a4, a5  --&gt; fp mulfp_div a6, a7  --&gt; fp div\n当每条指令走过 ID 阶段以后，会进入各自的功能单元执行，互不干扰。\nPipelined or Not-Pipelined·\n像大部分简单的 ALU 指令，比如加减法指令，通常只需要一个周期就能够完成，但由于存在长周期指令，比如，乘法指令，除法指令，由于其本身硬件实现的复杂性，所以基本上不可能一个在周期内完成（除非你压缩 CPU 的频率，让其一个周期的时间变长，但这没有意义），所以实际上每个功能单元占用的周期数是不同的。\n假设下面列举的流水线都是单发流水线，并且我们所有的功能单元同一时间只能执行一条指令，也就是说，同一周期，当进入一条指令以后，就不能再进入第二条使用相同功能单元的指令了。当出现如下顺序的汇编时，\nmul a0, a1mul a2, a3\n如果 mul 指令不能在一个周期完成执行，下一条 mul 就会进入在 MUL/DIV 功能单元之前被阻塞住，也就是出现了流水线暂停的行为。\n上述对 MUL/DIV 功能单元的描述，意思就是说，这个功能单元是非流水线化的（Not-Pipelined）。\n显然这种流水线是非常慢的，会出现大量因为功能单元被占用导致的流水线暂停，所以这里我们可以引入流水线化（Pipelined）的功能单元来进行加速，允许多个需要同一功能单元的指令同时进行。\nflowchart LR\n    IF[IF]\n    ID[ID]\n    INT_OP[Integer Unit]\n    FP_ADD0[FP Add/Sub Stage 0]\n    FP_ADD1[FP Add/Sub Stage 1]\n    FP_ADD2[FP Add/Sub Stage 2]\n    FP_MUL0[FP Mul Stage 0]\n    FP_MUL1[FP Mul Stage 1]\n    FP_MUL2[FP Mul Stage 2]\n    FP_MUL3[FP Mul Stage 3]\n    FP_DIV[FP DIV]\n    MUL0[MUL/DIV Stage 0]\n    MUL1[MUL/DIV Stage 1]\n    MUL2[MUL/DIV Stage 2]\n    MEM[MEM]\n    WB[WB]\n\n    IF --&gt;| | ID\n    ID --&gt;| | MUL0\n    ID --&gt;| | FP_DIV\n    ID --&gt;| | INT_OP\n    ID --&gt;| | FP_ADD0\n    ID --&gt;| | FP_MUL0\n    INT_OP --&gt;| | MEM\n    MUL2 --&gt;| | MEM\n    FP_ADD2 --&gt;| | MEM\n    FP_MUL3 --&gt;| | MEM\n    FP_DIV --&gt;| | MEM\n    MEM --&gt;| | WB\n\n    MUL0 --&gt; MUL1 \n    MUL1 --&gt; MUL2\n\n    FP_ADD0 --&gt; FP_ADD1\n    FP_ADD1 --&gt; FP_ADD2\n\n    FP_MUL0 --&gt; FP_MUL1\n    FP_MUL1 --&gt; FP_MUL2\n    FP_MUL2 --&gt; FP_MUL3\n为了解决上述性能瓶颈，我们将 MUL/DIV 单元流水线化至三级：\n\nStage 0：对操作数进行部分积预处理；\nStage 1：计算部分积；\nStage 2：生成最终结果并写入目标寄存器。\n\n\n这里只是举个例子，真实的情况大概率与我所说的不同，这里只是帮助理解如何进行功能单元的流水线化，具体乘法器到底是如何实现，要去阅读相关资料。\n\n在满载状态下，该流水线每个周期可以接受一条新的乘除法指令。虽然每条指令仍然需要 3 个周期才能完成，但由于各阶段可并发运行，总体吞吐率显著提升。\n在图中，FP Mul 单元，Mul/Div 单元以及 FP Add/Sub 单元均已被流水线化，该流水线可以同时执行四条浮点乘法指令，三条整数乘除法指令，三条浮点加减法指令，而 FP DIV由于没有流水线化，同一时刻只能有一条指令位于该功能单元内。\n\n这里 Integer Unit也是流水线化的，因为本身就用于执行单周期指令。\n\n当再次出现如下顺序的汇编时，流水线将不会因为资源占用导致暂停了。\nmul a0, a1mul a2, a3\n\n\n大部分功能单元都是流水线化的，但是像 FP Div 这种使用频率很少的功能单元，即使做成非流水线化，通常情况下很少会导致流水线暂停。（本身使用FP Div功能单元的指令就比较少，就算出现了多条使用该功能单元的指令，调度器也不会将它们排在一起。）因此，将使用频率很少的功能单元做成非流水线化的，不仅可以减少芯片流水线复杂度，也不会有明显的负面影响。\n这里把功能单元拆成多个 stages 是为了帮助理解，实际的流水线图不会这么画，一个功能单元是否是流水线化的也需要参考对应的白皮书文档。（很多流水线的实际信息都是需要从白皮书中获取的。）\n\n\nReal Pipeline·\n让我们来看一个真实的流水线图，这是晶心科技 Andes-D45 的流水线图。\n\n  \n  \n    Andes-D45 Pipeline (From \n    \n      andestech.com\n    \n    )\n  \n\n对应的流水线简化图如下，\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n\n    %% Pipelines\n    ALU0[ALU0]\n    ALU1[ALU1]\n    LDST[AGU + LD/ST]\n    FP[FP Pipeline]\n    MULDIV[MUL/DIV Pipeline]\n    DSP[DSP Pipeline]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; LDST\n    Issue0 --&gt; FP\n    Issue0 --&gt; MULDIV\n    Issue0 --&gt; DSP\nD45 由于是双发的流水线，一个周期会发射两条指令，考虑到 ALU 指令是最频繁的，为了可以同时双发两条 ALU 指令，它这里设置了两条 ALU 通路，也就是说，当出现下面两条汇编指令同时发射时，它们可以分别占用两条 ALU 通路，而不会导致流水线暂停。（可以想到，如果只有一条 ALU 通路的话，那么这里两条 add 指令就没法同时发射了，因为会有资源冲突，流水线会暂停。）\nadd a0, a1  --&gt; slot 0 -- use ALU0add a2, a3  --&gt; slot 1 -- use ALU1\nD45 的流水线是非常简单的，没有什么过多需要描述的地方。\n\n\nD45 的 ALU 还有一个特殊的地方，它将 ALU stages 划分为两个 stages，EX stage 和 LX stage（L 意味着 Later），这里设计的意图，可能是为了减少数据冲突导致的暂停。这个并不是主要要讨论的问题。\nDSP 单元是为了执行 Andes RISCV-P Extension 的特殊指令。\n\n\n另一个是 Sifive-P670 的流水线，它是一个乱序 4 发射的流水线，看起来可能稍微复杂一点，\n\n  \n  \n    Sifive-P670 Pipeline (From \n    \n      cnx-software.com\n    \n    )\n  \n\n从图上看，可能会感觉功能单元这么多又这么复杂，我们在这里主要看它功能单元的流水线构成，因此可以剖除乱序的单元，以及 Cache 等单元来看，也就是下图红框中的部分。\n\n对应的流水线简化图，可以表示成如下形式，\nflowchart LR\n    %% Issue paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n    Issue2[Slot 2]\n    Issue3[Slot 3]\n\n    %% ALU Pipelines\n    ALU_FULL[ALU0: ALU + MUL + DIV + I2F]\n    ALU_ONLY[ALU1: ALU]\n    BR0[BR0: BR]\n    BR1[BR1: BR]\n\n    %% LD/SD Pipelines\n    LDST0[LD/ST0: AGU + LD/ST]\n    LDST1[LD/ST1: AGU + LD/ST]\n\n    %% FP Pipelines\n    FP0[FP0: FMAC + FADD + FMUL + I2F]\n    FP1[FP1: FMAC + FADD + FMUL + FDIV]\n\n    %% Vector Pipelines\n    VEC0[Vector0: ALU + DIV]\n    VEC1[Vector1: ALU + V2S]\n\n    %% Connections from Issue paths\n    Issue0 --&gt; ALU_FULL\n    Issue0 --&gt; ALU_ONLY\n    Issue0 --&gt; BR0\n    Issue0 --&gt; BR1\n\n    Issue0 --&gt; LDST0\n    Issue0 --&gt; LDST1\n\n    Issue0 --&gt; FP0\n    Issue0 --&gt; FP1\n\n    Issue0 --&gt; VEC0\n    Issue0 --&gt; VEC1\n如果我们把它当做一个四发射顺序核来看的话，这个流水线在遇到如下汇编的时候，\nmul a1, a1, a2    \t--&gt; solt0 -- use the ALU0 pipebeqz a3, .label0  \t--&gt; solt1 -- use the BR0 pipeaddi a0, a0, 1    \t--&gt; solt2 -- use the ALU1 pipebeqz a4, .label1  \t--&gt; solt3 -- use the BR1 pipelw a5, 8(sp)\t\t--&gt;\tslot0 -- use the LD/ST0 pipelw a6, 12(sp)\t\t--&gt;\tslot1 -- use the LD/ST1 pipefadd fa3, fa4, fa5\t--&gt;\tslot2 -- use the FP0 pipefdiv fa0, fa1, fa2\t--&gt;\tslot3 -- use the FP1 pipe\nPipeline Stalls·\n\n本文前面说了这么多，就是为了铺垫这个东西 😉\n我们这里暂时不考虑乱序核的情况，先理解顺序核中的性能损失情况，在此基础上再去理解乱序核会更好。\n\nTypes of stall·\n现代 CPU 可能因为各种各样的原因导致流水线性能损失，\n比如 iCache miss 会导致 IF 阶段无法顺利取到下一条指令，没有指令，流水线自然只能在那里空转，这导致了一些性能损失。又或者，如果一条汇编对应多个微操作（micro-ops）的话，在解码阶段可能会花费多个周期，也有可能导致后半部分流水线的空转。这些性能损失都是由于流水线前端无法给流水线后端提供足够的指令所导致的，通常被称为流水线前端暂停。\n\n这种情况在 CISC 指令集中（如 x86）中较为常见，一条汇编翻译出来的微操作（micro-op）数量过多可能会导致 decode/dispatch 阶段变成瓶颈，进而影响整体吞吐率。而 RISC 指令集通常一条汇编对应一个微操作，通常不会发生这种问题。\n\n又比如，当流水线中同时出现两条指令，它们需要相同的功能单元，而这条流水线只有一个该功能单元时，会发生结构冲突或资源冲突，流水线必须暂停等待上一条指令释放该资源。\n比如在 Andes-D45 流水线中，\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n\n    %% Pipelines\n    ALU0[ALU0]\n    ALU1[ALU1]\n    LDST[AGU + LD/ST]\n    FP[FP Pipeline]\n    MULDIV[MUL/DIV Pipeline]\n    DSP[DSP Pipeline]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; LDST\n    Issue0 --&gt; FP\n    Issue0 --&gt; MULDIV\n    Issue0 --&gt; DSP\n假如出现以下汇编，则由于乘法单元只有一个，同时双发两条 mul指令必然会导致流水线暂停，\nmul a0, a1, a2  --&gt; slot 0 -- use the MUL/DIV pipemul a3, a4, a5  --&gt; slot 1 -- the MUL/DIV pipe was occupied, so it had to wait\n再看如下汇编，显然，这对汇编不会发生资源冲突，一个进入 MUL/DIV功能单元执行乘法运算，一个进入ALU功能单元执行加法指令，非常和谐。\nmul a0, a1, a2  --&gt; slot 0 -- write `a0`, assuming it can be read after 2 cycles.add a3, a0, a5  --&gt; slot 1 -- read `a0` from `mul`, so it had to wait 2 cycles.\n但是不和谐的地方在于，第二条add指令使用了前一条mul指令要写的值，这就是另一中很常见的冲突 – 数据冲突，数据冲突通常分为三类，写后读，读后写，写后写，对应数据依赖（True Dependency/Data Dependency），反依赖（Anti-Dependency），输出依赖（Output-Dependency），具体定义不在这里赘述。\n上述由于冲突导致的流水线损失，通常表现为流水线完全暂停等待冲突解除，被称为流水线后端暂停。\nWhat can be solved by the scheduler?·\n既然本系列是介绍调度模型的，自然需要知道，调度器是用来解决哪些流水线暂停问题的。\n调度器的主要作用，是在代码局部，通常是在一个基本块内，进行指令重排布。它会在不影响代码逻辑正确性的情况下尽可能的减少可能的流水线暂停。所以这个问题就是，对指令进行重排布，可以解决掉哪些可能的流水线暂停？\n其实答案就是上节提到的几个流水线暂停的类型: 指令解码过于复杂导致的前端流水线暂停，以及资源冲突，数据冲突导致的后端流水线暂停。\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n\n    %% Pipelines\n    ALU0[ALU0]\n    ALU1[ALU1]\n    LDST[AGU + LD/ST]\n    FP[FP Pipeline]\n    MULDIV[MUL/DIV Pipeline]\n    DSP[DSP Pipeline]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; LDST\n    Issue0 --&gt; FP\n    Issue0 --&gt; MULDIV\n    Issue0 --&gt; DSP\n还是以 D45 流水线举例，假设遇到如下汇编，流水线会如何执行？\nmul a0, a1, a2mul a3, a4, a5add t0, a0, a3add t0, t2, 1add t1, t1, 1add a0, a0, 1add t3, t3, 1\n首先，两条mul指令是不能双发的，因为它们同时需要使用 MUL/DIV 单元，所以第一个周期，它只能发射一条mul指令，第二条mul指令需要等到下一个周期才能发射。\n当两条mul发射以后，add t0, a0, a3由于与前两条mul都有数据依赖，假设mul发射以后 3 个周期，add指令才能读取这个操作数，则add t0, a0, a3需要停顿 3 个周期才能发射。而第 5 个周期，由于add t0, a0, a3和 add t0, t2, 1它们之间有输出依赖，仍然无法双发。\n-- cycle1 --mul a0, a1, a2-- cycle2 --mul a3, a4, a5-- cycle5 --add t0, a0, a3-- cycle6 --add t0, t2, 1-- cycle7 --add t1, t1, 1add a0, a0, 1-- cycle8 --add t3, t3, 1\n让我们手动调度一下这个汇编代码，\nmul a0, a1, a2add t1, t1, 1mul a3, a4, a5add t3, t3, 1add t0, a0, a3add a0, a0, 1add t0, t2, 1\n在两条mul指令之间，插入一条add t1, t1, 1，消除了资源冲突导致的流水线暂停。在存在数据依赖的mul和add之间，插入一条add t3, t3, 1，虽然没有完全消除数据依赖导致的流水线暂停，但是相同的周期数内执行的指令数更多了。在存在输出依赖的两条add之间，插入一条add a0, a0, 1，消除了输出依赖导致的流水线暂停。\n-- cycle1 --mul a0, a1, a2add t1, t1, 1-- cycle2 --mul a3, a4, a5add t3, t3, 1-- cycle5 --add t0, a0, a3add a0, a0, 1-- cycle6 --add t0, t2, 1\n总结来说，调度器通过重新排布指令的执行顺序，来缓解如下几类性能瓶颈：\n\n解码阶段阻塞：例如某些复杂指令被翻译为多个微操作，导致流水线吞吐下降\n结构冲突 / 资源冲突：多条指令竞争同一个功能单元\n数据冲突：典型如写后读（RAW）依赖引起的等待\n\n\n而一些系统性延迟，如 Cache Miss（iCache 或 dCache）、分支预测失败等，通常不是调度器能直接解决的，这类 暂停更多依赖于体系结构本身的优化策略或预取机制。当前，编译器也有比如基本块重排布优化（BasicBlockPlacement），来解决分支预测问题。\n\n所以，调度器并不能解决所有类型的流水线暂停，但它在提升执行单元利用率、隐藏延迟、减少流水线空泡等方面是至关重要的。理解这一点，是编写调度模型之前必须要建立的认知基础。\nReferences·\n\n计算机体系结构：量化研究方法（第6版）附录 C\nWhat are Front-End Stalls and Back-End Stalls ? – from stackoverflow\n\n","tags":["instruction scheduling"]},{"title":"What We Need in a Scheduling Model","url":"/2025/05/27/Scheduling-Models-2/","content":"Framework·\n\nUnderstanding In-Order Pipelines and Pipeline Stalls\nWhat We Need in a Scheduling Model: GCC and LLVM Perspectives\nWriting a Scheduling Model from Scratch\nTuning Your Scheduling Model for Better Performance\nRecommended Readings on Out-of-Order Execution and Scheduling\n\nLet’s Recap·\n第一篇文章中，我们已经说过，调度器主要是用来解决三类冲突，\n\n解码过于复杂导致的流水线前端暂停（后面简称为解码暂停）\n指令争夺相同运算单元导致流水线暂停的结构冲突\n指令间存在寄存器读写依赖导致流水线暂停的数据冲突\n\n这一节我们将详细展开，并且说明如果我们想要解决这些导致流水线暂停的冲突，我们需要哪些具体的流水线信息。\nLet’s Think·\nRelationship between Scheduling Model and Scheduling Algorithm·\n在讨论调度模型需要哪些信息之前，我们先简单介绍一下目前最广泛使用的调度算法，列表调度算法（List Scheduling Algorithm）。它通常是在基本块内部进行的，通过在满足依赖关系的前提下，重排指令顺序，以尽可能提升流水线的利用率。\n整个列表调度的基本流程可以概括为，\n\n首先，扫描基本块中的所有汇编指令，构建一张有向无环图（DAG）。图中的每个节点代表一条指令，边代表指令之间的依赖关系（如 RAW、WAW）。\n接着，对 DAG 进行调度，调度的过程就是使用一系列启发式策略对就绪指令进行拓扑排序的过程。\n\n\n就绪指令的意思是，这条指令在不存在任何冲突，即所有依赖都已满足的指令，可以“安全”地发射出去。\n\n那么问题来了，如何判断一条指令是就绪指令呢？\n\n比如上一节中我们作为例子的汇编代码，\nmul a0, a1, a2mul a3, a4, a5add t0, a0, a3add t0, t2, 1add t1, t1, 1add a0, a0, 1add t3, t3, 1\n它对应的 DAG 图如下，\ngraph TD\n    A0[mul a0, a1, a2]\n    A1[mul a3, a4, a5]\n    A2[add t0, a0, a3]\n    A3[add t0, t2, 1]\n    A4[add t1, t1, 1]\n    A5[add a0, a0, 1]\n    A6[add t3, t3, 1]\n\n    A0 -- RAW --&gt; A2\n    A1 -- RAW --&gt; A2\n    A2 -- WAW --&gt; A3\n    A0 -- RAW --&gt; A5\n显然，刚开始我们有四条就绪指令，即四条入度为 0 的指令，\n=== Ready List ===[mul a0, a1, a2], [mul a3, a4, a5], [add t1, t1, 1], [add t3, t3, 1]\n假设调度器选择mul a0, a1, a2指令进行调度以后，就绪指令会如何变化？\ngraph TD\n    A0[mul a0, a1, a2]\n    A1[mul a3, a4, a5]\n    A2[add t0, a0, a3]\n    A3[add t0, t2, 1]\n    A4[add t1, t1, 1]\n    A5[add a0, a0, 1]\n    A6[add t3, t3, 1]\n\n    A0 ~~~ A2\n    A1 -- RAW --&gt; A2\n    A2 -- WAW --&gt; A3\n    A0 ~~~ A5\nadd a0, a0, 1已经入度为 0，它是否可以直接加入就绪队列，或者什么时候它可以被加入就绪队列？mul a3, a4, a5是否与上一条被调度的指令有结构冲突，它是否需要被剔出就绪队列？\n显然这个问题，我们在没有任何信息的情况下，是无法判断的，因为这是平台相关的信息，是由硬件流水线决定的。所以，我们就需要调度模型来解决这些问题了，我们需要给流水线进行建模，在建立的模型中包含以上信息，提供给调度算法查询，基于这些信息，调度算法才能做出更优的判断。因此，调度器可以认为是调度算法与调度模型共同组成的。如果没有调度模型，调度算法就无法获取流水线信息，只能基于默认的假设值来做调度，那么自然调度的效果就不会太好。\n因此，我们可以这样定义调度模型（Scheduling Model）：调度模型是一组用于抽象目标架构中流水线行为的参数集合，它描述了指令在硬件上的资源需求、延迟特性、执行约束等信息，供调度算法参考与查询，从而生成更符合硬件实际的指令排列方案。\n它通常会回答如下问题：\n\n同一个周期内最多能发射几条指令？\n发射一条指令时，会占用哪些资源？资源是否冲突？\n一条指令的输出什么时候可被下一条使用？\n\n这些信息对顺序核调度尤为关键，因为这些核心无法自动乱序调度、规避冲突，只能依赖静态调度器的来尽可能高效地填满流水线。\n","tags":["instruction scheduling"]}]