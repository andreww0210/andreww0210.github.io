[{"title":"How to use hexo","url":"/2022/02/10/How-to-use-hexo/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start·\nCreate a new post·\n$ hexo new &quot;My New Post&quot;\nMore info: Writing\nRun server·\n$ hexo server\nMore info: Server\nGenerate static files·\n$ hexo generate\nMore info: Generating\nDeploy to remote sites·\n$ hexo deploy\nMore info: Deployment\n"},{"title":"It's my Hello,World!","url":"/2023/11/17/My-Hello-World/","content":"这是我的第一篇博客，作为“程序员”的我，理应叫他&quot;Hello,World!&quot;\n(其实我不太喜欢“程序员”这个称呼，因为总感觉它带着一些刻板印象在里面。)\nIntroduce myself·\n第一篇也也不知道说些什么，就随便唠叨唠叨了。\n那就先介绍一下自己。个人目前是在武汉做LLVM编译器开发，目前主要的工作是做编译优化。当初因为很喜欢计算机底层知识，所以选择了这个方向。可能由于国内做编译器的很少，所以同行竞争压力比较小，加上我们的老板和总监之前都是常年在国外创业和工作，所以工作氛围很轻松，而且工作时间是真的弹性965。\n但是工作压力还是有的，主要是因为编译器软件过于庞大，计算机底层知识牵涉过多，所以有时候举步维艰。所以这也是我花费周末时间搭这个博客的一点原因，想借助这个博客来记录自己的学习。当然其实更多的是兴趣使然，不然我是不可能凌晨熬夜还在看这个前端代码的。\n工作五个月，从最开始接触linux指令，跑测试，整理数据，到开始做code size相关的优化（主要是outline相关），现在由于公司要用picolibc库开发，所以最近都在和picolibc打交道，所以也接触到了很多链接器相关的东西。我的工作其实说起来很无聊，就是测试，对比，阅读LLVM源码，在源码基础上做优化，但我很喜欢我的工作，可能本身对计算机底层的兴趣使我不会那么厌烦。工作中有很多很难的东西，比如要去阅读上千上万行的源码，虽然LLVM已经有十多年的时间了，但是能参考的资料真的不是很多，而且几乎没有中文，只能硬着头皮去看英文文档。遇到特别难的东西，其实真的也会很暴躁。😦\n结果就是，在技术方面，我真的成长了许多，但现在仍然还是个菜鸡。\n\nAbout my life·\n我也很喜欢我的生活，也有很多想做的事情。\n曾经刚来武汉的一段时间，我非常暴躁，大概是因为一个人来到一座城市，没有亲人朋友的孤独感。每天打开房门，面对的就是一个黑咕隆咚的地方，好像要被吞进去，打开灯，当然仍旧是走之前的老样子，没人陪伴孤独的样子。\n现在倒是好多了，或许是因为我放下了一些执念？又或许是我看了一些书？who knows，总之真的在变好了，无论是面对的生活，还是在情绪上。希望以后会越来越好。\nHappy ending·\n总之，搭这个博客的目的，主要就是为了记录自己的生活和学习。这里也算是我自己的小天地了。\n","tags":["Hello,Wolrd!"]},{"title":"In-Order Pipeline and Pipeline Stalls","url":"/2025/05/16/Scheduling-Models-1/","content":"Framework·\n\nUnderstanding In-Order Pipelines and Pipeline Stalls\nWhat We Need in a Scheduling Model\nScheduling Model: GCC and LLVM Perspectives\nTuning Your Scheduling Model for Better Performance\nRecommended Readings on Out-of-Order Execution and Scheduling\n\nExtended in-order pipeline·\nExtended EX stage pipeline·\n\n我不想在这里讨论基本的五级顺序流水线概念，你可以在任何一本介绍计算机体系结构的书上找到相关的内容，所以我会假设你已经了解基本的顺序流水线知识、流水线冒险（结构冒险、数据冒险、控制冒险）、数据前推，如果你对提到的任何关键词有疑问，请先补充相关的知识 😉\n\nflowchart LR\n    IF[IF]\n    ID[ID]\n    EX[EX]\n    MEM[MEM]\n    WB[WB]\n\n    IF --&gt; ID\n    ID --&gt; EX\n    EX --&gt; MEM\n    MEM --&gt; WB\n如上图，基本的五级流水线（取指，译码，执行，访存，写回）由于做了简化，并没有暴露其中的细节。从图中看起来所有的执行单元被抽象成一个 EX stage，而真实的 CPU 流水线不仅要处理基本的整数运算，还需要处理浮点运算以及它们各自的加减乘除，所以一个完整的 EX stage 至少会包括 ALU 单元运算，乘法除法器运算单元，浮点加减运算单元，浮点乘除运算单元。\n假设我们有一个可以处理各种整数运算，浮点加减乘除运算的流水线，从黑盒子的角度来看，它可能长成下图这个样子。\n\nflowchart LR\n    IF[IF]\n    ID[ID]\n    INT_OP[Integer Unit]\n    FP_ADD[FP Add/Sub]\n    FP_MUL[FP Mul]\n    FP_DIV[FP DIV]\n    MUL[MUL/DIV]\n    MEM[MEM]\n    WB[WB]\n\n    IF --&gt;| | ID\n    ID --&gt;| | MUL\n    ID --&gt;| | FP_DIV\n    ID --&gt;| | INT_OP\n    ID --&gt;| | FP_ADD\n    ID --&gt;| | FP_MUL\n    MUL --&gt;| | MEM\n    INT_OP --&gt;| | MEM\n    FP_ADD --&gt;| | MEM\n    FP_MUL --&gt;| | MEM\n    FP_DIV --&gt;| | MEM\n    MEM --&gt;| | WB\n\n不同硬件实现不同，可能有些流水线会把一些功能单元做合并或拆分，比如将 MUL 和 DIV 分开，分别负责整数乘法和除法。\n\n假设我们现在有这样一段汇编代码，\nadd    a0, a1  --&gt; integer unitmul    a2, a3  --&gt; mul/divfp_mul a4, a5  --&gt; fp mulfp_div a6, a7  --&gt; fp div\n当每条指令走过 ID 阶段以后，会进入各自的功能单元执行，互不干扰。\nPipelined or Not-Pipelined·\n像大部分简单的 ALU 指令，比如加减法指令，通常只需要一个周期就能够完成，但由于存在长周期指令，比如，乘法指令，除法指令，由于其本身硬件实现的复杂性，所以基本上不可能一个在周期内完成（除非你压缩 CPU 的频率，让其一个周期的时间变长，但这没有意义），所以实际上每个功能单元占用的周期数是不同的。\n假设下面列举的流水线都是单发流水线，并且我们所有的功能单元同一时间只能执行一条指令，也就是说，同一周期，当进入一条指令以后，就不能再进入第二条使用相同功能单元的指令了。当出现如下顺序的汇编时，\nmul a0, a1mul a2, a3\n如果 mul 指令不能在一个周期完成执行，下一条 mul 就会进入在 MUL/DIV 功能单元之前被阻塞住，也就是出现了流水线暂停的行为。\n上述对 MUL/DIV 功能单元的描述，意思就是说，这个功能单元是非流水线化的（Not-Pipelined）。\n显然这种流水线是非常慢的，会出现大量因为功能单元被占用导致的流水线暂停，所以这里我们可以引入流水线化（Pipelined）的功能单元来进行加速，允许多个需要同一功能单元的指令同时进行。\nflowchart LR\n    IF[IF]\n    ID[ID]\n    INT_OP[Integer Unit]\n    FP_ADD0[FP Add/Sub Stage 0]\n    FP_ADD1[FP Add/Sub Stage 1]\n    FP_ADD2[FP Add/Sub Stage 2]\n    FP_MUL0[FP Mul Stage 0]\n    FP_MUL1[FP Mul Stage 1]\n    FP_MUL2[FP Mul Stage 2]\n    FP_MUL3[FP Mul Stage 3]\n    FP_DIV[FP DIV]\n    MUL0[MUL/DIV Stage 0]\n    MUL1[MUL/DIV Stage 1]\n    MUL2[MUL/DIV Stage 2]\n    MEM[MEM]\n    WB[WB]\n\n    IF --&gt;| | ID\n    ID --&gt;| | MUL0\n    ID --&gt;| | FP_DIV\n    ID --&gt;| | INT_OP\n    ID --&gt;| | FP_ADD0\n    ID --&gt;| | FP_MUL0\n    INT_OP --&gt;| | MEM\n    MUL2 --&gt;| | MEM\n    FP_ADD2 --&gt;| | MEM\n    FP_MUL3 --&gt;| | MEM\n    FP_DIV --&gt;| | MEM\n    MEM --&gt;| | WB\n\n    MUL0 --&gt; MUL1 \n    MUL1 --&gt; MUL2\n\n    FP_ADD0 --&gt; FP_ADD1\n    FP_ADD1 --&gt; FP_ADD2\n\n    FP_MUL0 --&gt; FP_MUL1\n    FP_MUL1 --&gt; FP_MUL2\n    FP_MUL2 --&gt; FP_MUL3\n为了解决上述性能瓶颈，我们将 MUL/DIV 单元流水线化至三级：\n\nStage 0：对操作数进行部分积预处理；\nStage 1：计算部分积；\nStage 2：生成最终结果并写入目标寄存器。\n\n\n这里只是举个例子，真实的情况大概率与我所说的不同，这里只是帮助理解如何进行功能单元的流水线化，具体乘法器到底是如何实现，要去阅读相关资料。\n\n在满载状态下，该流水线每个周期可以接受一条新的乘除法指令。虽然每条指令仍然需要 3 个周期才能完成，但由于各阶段可并发运行，总体吞吐率显著提升。\n在图中，FP Mul 单元，Mul/Div 单元以及 FP Add/Sub 单元均已被流水线化，该流水线可以同时执行四条浮点乘法指令，三条整数乘除法指令，三条浮点加减法指令，而 FP DIV由于没有流水线化，同一时刻只能有一条指令位于该功能单元内。\n\n这里 Integer Unit也是流水线化的，因为本身就用于执行单周期指令。\n\n当再次出现如下顺序的汇编时，流水线将不会因为资源占用导致暂停了。\nmul a0, a1mul a2, a3\n\n\n大部分功能单元都是流水线化的，但是像 FP Div 这种使用频率很少的功能单元，即使做成非流水线化，通常情况下很少会导致流水线暂停。（本身使用FP Div功能单元的指令就比较少，就算出现了多条使用该功能单元的指令，调度器也不会将它们排在一起。）因此，将使用频率很少的功能单元做成非流水线化的，不仅可以减少芯片流水线复杂度，也不会有明显的负面影响。\n这里把功能单元拆成多个 stages 是为了帮助理解，实际的流水线图不会这么画，一个功能单元是否是流水线化的也需要参考对应的白皮书文档。（很多流水线的实际信息都是需要从白皮书中获取的。）\n\n\nReal Pipeline·\n让我们来看一个真实的流水线图，这是晶心科技 Andes-D45 的流水线图。\n\n  \n  \n    Andes-D45 Pipeline (From \n    \n      andestech.com\n    \n    )\n  \n\n对应的流水线简化图如下，\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n\n    %% Pipelines\n    ALU0[ALU0]\n    ALU1[ALU1]\n    LDST[AGU + LD/ST]\n    FP[FP Pipeline]\n    MULDIV[MUL/DIV Pipeline]\n    DSP[DSP Pipeline]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; LDST\n    Issue0 --&gt; FP\n    Issue0 --&gt; MULDIV\n    Issue0 --&gt; DSP\nD45 由于是双发的流水线，一个周期会发射两条指令，考虑到 ALU 指令是最频繁的，为了可以同时双发两条 ALU 指令，它这里设置了两条 ALU 通路，也就是说，当出现下面两条汇编指令同时发射时，它们可以分别占用两条 ALU 通路，而不会导致流水线暂停。（可以想到，如果只有一条 ALU 通路的话，那么这里两条 add 指令就没法同时发射了，因为会有资源冲突，流水线会暂停。）\nadd a0, a1  --&gt; slot 0 -- use ALU0add a2, a3  --&gt; slot 1 -- use ALU1\nD45 的流水线是非常简单的，没有什么过多需要描述的地方。\n\n\nD45 的 ALU 还有一个特殊的地方，它将 ALU stages 划分为两个 stages，EX stage 和 LX stage（L 意味着 Later），这里设计的意图，可能是为了减少数据冲突导致的暂停。这个并不是主要要讨论的问题。\nDSP 单元是为了执行 Andes RISCV-P Extension 的特殊指令。\n\n\n另一个是 Sifive-P670 的流水线，它是一个乱序 4 发射的流水线，看起来可能稍微复杂一点，\n\n  \n  \n    Sifive-P670 Pipeline (From \n    \n      cnx-software.com\n    \n    )\n  \n\n从图上看，可能会感觉功能单元这么多又这么复杂，我们在这里主要看它功能单元的流水线构成，因此可以剖除乱序的单元，以及 Cache 等单元来看，也就是下图红框中的部分。\n\n对应的流水线简化图，可以表示成如下形式，\nflowchart LR\n    %% Issue paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n    Issue2[Slot 2]\n    Issue3[Slot 3]\n\n    %% ALU Pipelines\n    ALU_FULL[ALU0: ALU + MUL + DIV + I2F]\n    ALU_ONLY[ALU1: ALU]\n    BR0[BR0: BR]\n    BR1[BR1: BR]\n\n    %% LD/SD Pipelines\n    LDST0[LD/ST0: AGU + LD/ST]\n    LDST1[LD/ST1: AGU + LD/ST]\n\n    %% FP Pipelines\n    FP0[FP0: FMAC + FADD + FMUL + I2F]\n    FP1[FP1: FMAC + FADD + FMUL + FDIV]\n\n    %% Vector Pipelines\n    VEC0[Vector0: ALU + DIV]\n    VEC1[Vector1: ALU + V2S]\n\n    %% Connections from Issue paths\n    Issue0 --&gt; ALU_FULL\n    Issue0 --&gt; ALU_ONLY\n    Issue0 --&gt; BR0\n    Issue0 --&gt; BR1\n\n    Issue0 --&gt; LDST0\n    Issue0 --&gt; LDST1\n\n    Issue0 --&gt; FP0\n    Issue0 --&gt; FP1\n\n    Issue0 --&gt; VEC0\n    Issue0 --&gt; VEC1\n如果我们把它当做一个四发射顺序核来看的话，这个流水线在遇到如下汇编的时候，\nmul a1, a1, a2    \t--&gt; solt0 -- use the ALU0 pipebeqz a3, .label0  \t--&gt; solt1 -- use the BR0 pipeaddi a0, a0, 1    \t--&gt; solt2 -- use the ALU1 pipebeqz a4, .label1  \t--&gt; solt3 -- use the BR1 pipelw a5, 8(sp)\t\t--&gt;\tslot0 -- use the LD/ST0 pipelw a6, 12(sp)\t\t--&gt;\tslot1 -- use the LD/ST1 pipefadd fa3, fa4, fa5\t--&gt;\tslot2 -- use the FP0 pipefdiv fa0, fa1, fa2\t--&gt;\tslot3 -- use the FP1 pipe\nPipeline Stalls·\n\n本文前面说了这么多，就是为了铺垫这个东西 😉\n我们这里暂时不考虑乱序核的情况，先理解顺序核中的性能损失情况，在此基础上再去理解乱序核会更好。\n\nTypes of stall·\n现代 CPU 可能因为各种各样的原因导致流水线性能损失，\n比如 iCache miss 会导致取指阶段无法及时取到下一条指令，流水线前端得不到新指令，流水线只能空转等待，从而引发性能损失。而即使取到了指令，如果一条指令在解码后被翻译成多个微操作（micro-ops），而流水线的发射宽度（Issue width）不匹配时，需要多个周期才能完成当前所有微操作的发射，前端流水线同样会暂停。\n这些性能损失的根源都是因为前端流水线无法持续、稳定地提供指令给后端，通常被统称为流水线前端暂停。\n\n这种由于微操作数量与发射宽度不匹配导致的流水线前端暂停（后面称之为发射阻塞），在 CISC 指令集中（如 x86）中较为常见，而 RISC 指令通常结构比较简单，一条汇编对应一到两个微操作，通常不会发生这种问题。\n\n又比如，当流水线中同时出现两条指令，它们需要相同的功能单元，而这条流水线只有一个该功能单元时，会发生结构冲突或资源冲突，流水线必须暂停等待上一条指令释放该资源。\n在 Andes-D45 流水线中，\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n\n    %% Pipelines\n    ALU0[ALU0]\n    ALU1[ALU1]\n    LDST[AGU + LD/ST]\n    FP[FP Pipeline]\n    MULDIV[MUL/DIV Pipeline]\n    DSP[DSP Pipeline]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; LDST\n    Issue0 --&gt; FP\n    Issue0 --&gt; MULDIV\n    Issue0 --&gt; DSP\n假如出现以下汇编，则由于乘法单元只有一个，同时双发两条 mul指令必然会导致流水线暂停，\nmul a0, a1, a2  --&gt; slot 0 -- use the MUL/DIV pipemul a3, a4, a5  --&gt; slot 1 -- the MUL/DIV pipe was occupied, so it had to wait\n进一步再看如下汇编，显然，这对汇编不会发生资源冲突，一个进入 MUL/DIV功能单元执行乘法运算，一个进入ALU功能单元执行加法指令，非常和谐。\nmul a0, a1, a2  --&gt; slot 0 -- write `a0`, assuming it can be read after 2 cycles.add a3, a0, a5  --&gt; slot 1 -- read `a0` from `mul`, so it had to wait 2 cycles.\n但是不和谐的地方在于，第二条add指令使用了前一条mul指令要写的值，这就是另一中很常见的冲突 – 数据冲突，数据冲突通常分为三类，写后读，读后写，写后写，对应数据依赖（True Dependency/Data Dependency），反依赖（Anti-Dependency），输出依赖（Output-Dependency），具体定义不在这里赘述。\n上述由于冲突导致的流水线损失，通常表现为流水线完全暂停等待冲突解除，被称为流水线后端暂停。\nWhat can be solved by the scheduler?·\n既然本系列是介绍调度模型的，自然需要知道，调度器是用来解决哪些流水线暂停问题的。\n调度器的主要作用，是在代码局部，通常是在一个基本块内，进行指令重排布。它会在不影响代码逻辑正确性的情况下尽可能的减少可能的流水线暂停。所以这个问题就是，对指令进行重排布，可以解决掉哪些可能的流水线暂停？\n其实答案就是上节提到的几个流水线暂停的类型: 发射阻塞导致的前端流水线暂停，以及资源冲突，数据冲突导致的后端流水线暂停。\n\n发射阻塞，其实本质上也是一种资源冲突，相当于多个微操作在争夺比它们数量少的发射通路。但是这里分开来看会更好理解一些。\n\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n\n    %% Pipelines\n    ALU0[ALU0]\n    ALU1[ALU1]\n    LDST[AGU + LD/ST]\n    FP[FP Pipeline]\n    MULDIV[MUL/DIV Pipeline]\n    DSP[DSP Pipeline]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; LDST\n    Issue0 --&gt; FP\n    Issue0 --&gt; MULDIV\n    Issue0 --&gt; DSP\n还是以 D45 流水线举例，假设遇到如下汇编，流水线会如何执行？\nmul a0, a1, a2mul a3, a4, a5add t0, a0, a3add t0, t2, 1add t1, t1, 1add a0, a0, 1add t3, t3, 1\n首先，两条mul指令是不能双发的，因为它们同时需要使用 MUL/DIV 单元，所以第一个周期，它只能发射一条mul指令，第二条mul指令需要等到下一个周期才能发射。\n当两条mul发射以后，add t0, a0, a3由于与前两条mul都有数据依赖，假设mul发射以后 3 个周期，add指令才能读取这个操作数，则add t0, a0, a3需要停顿 3 个周期才能发射。而第 5 个周期，由于add t0, a0, a3和 add t0, t2, 1它们之间有输出依赖，仍然无法双发。\n-- cycle1 --mul a0, a1, a2-- cycle2 --mul a3, a4, a5-- cycle5 --add t0, a0, a3-- cycle6 --add t0, t2, 1-- cycle7 --add t1, t1, 1add a0, a0, 1-- cycle8 --add t3, t3, 1\n让我们手动调度一下这个汇编代码，\nmul a0, a1, a2add t1, t1, 1mul a3, a4, a5add t3, t3, 1add t0, a0, a3add a0, a0, 1add t0, t2, 1\n在两条mul指令之间，插入一条add t1, t1, 1，消除了资源冲突导致的流水线暂停。在存在数据依赖的mul和add之间，插入一条add t3, t3, 1，虽然没有完全消除数据依赖导致的流水线暂停，但是相同的周期数内执行的指令数更多了。在存在输出依赖的两条add之间，插入一条add a0, a0, 1，消除了输出依赖导致的流水线暂停。\n-- cycle1 --mul a0, a1, a2add t1, t1, 1-- cycle2 --mul a3, a4, a5add t3, t3, 1-- cycle5 --add t0, a0, a3add a0, a0, 1-- cycle6 --add t0, t2, 1\n总结来说，调度器通过重新排布指令的执行顺序，来缓解如下几类性能瓶颈：\n\n发射阻塞：例如某些复杂指令被翻译为多个微操作，无法在一个周期完成发射\n结构冲突 / 资源冲突：多条指令竞争同一个功能单元\n数据冲突：典型如写后读（RAW）依赖引起的等待\n\n\n而一些系统性延迟，如 Cache Miss（iCache 或 dCache）、分支预测失败等，通常不是调度器能直接解决的，这类 暂停更多依赖于体系结构本身的优化策略或预取机制。当前，编译器也有比如基本块重排布优化（BasicBlockPlacement），来解决分支预测问题。\n\n所以，调度器并不能解决所有类型的流水线暂停，但它在提升执行单元利用率、隐藏延迟、减少流水线空泡等方面是至关重要的。理解这一点，是编写调度模型之前必须要建立的认知基础。\nReferences·\n\n计算机体系结构：量化研究方法（第6版）附录 C\nWhat are Front-End Stalls and Back-End Stalls ? – from stackoverflow\n\n","tags":["instruction scheduling"]},{"title":"What We Need in a Scheduling Model","url":"/2025/05/27/Scheduling-Models-2/","content":"Framework·\n\nUnderstanding In-Order Pipelines and Pipeline Stalls\nWhat We Need in a Scheduling Model\nScheduling Model: GCC and LLVM Perspectives\nTuning Your Scheduling Model for Better Performance\nRecommended Readings on Out-of-Order Execution and Scheduling\n\nRecap·\n第一篇文章中，我们已经说过，调度器主要是用来解决三类冲突，\n\n汇编解码出的微操作数过多，无法在一个周期内发射出去所导致的发射阻塞\n指令争夺相同运算单元导致流水线暂停的结构冲突\n指令间存在寄存器读写依赖导致流水线暂停的数据冲突\n\n这一节我们将详细展开，并且说明如果我们想要解决这些导致流水线暂停的冲突，我们需要哪些具体的流水线信息。\nModel it·\n假设我们现在不知道调度模型需要包含什么信息，目前先构建一个空的结构体定义struct Pipeline，后面我们将逐渐完善这个结构体内的变量定义。\n\n这个调度模型定义，即不是 LLVM 中的用法，也不是 gcc 中的用法，在这里是用更简单的方式表述，后面我们才会延伸到 LLVM 和 gcc 中的用法。\n\nstruct Pipeline &#123;  // Contains nothing.  // We don&#x27;t yet know what we need to model a pipeline.&#125;;\n\nScheduling Model and Scheduling Algorithm·\n在讨论调度模型需要哪些信息之前，我们先简单介绍一下目前最广泛使用的调度算法，列表调度算法（List Scheduling Algorithm）。它通常是在基本块内部进行的，通过在满足依赖关系的前提下，重排指令顺序，以尽可能提升流水线的利用率。\n整个列表调度的基本流程可以概括为，\n\n首先，扫描基本块中的所有汇编指令，构建一张有向无环图（DAG）。图中的每个节点代表一条指令，边代表指令之间的依赖关系（如 RAW、WAW）。\n接着，对 DAG 进行调度，调度的过程就是使用一系列启发式策略对就绪指令进行拓扑排序的过程。\n\n\n就绪指令的意思是，这条指令在不存在任何冲突，即所有依赖都已满足的指令，可以“安全”地发射出去。\n\n那么问题来了，如何判断一条指令是就绪指令呢？\n比如上一节中我们作为例子的汇编代码，\nmul a0, a1, a2mul a3, a4, a5add t0, a0, a3add t0, t2, 1add t1, t1, 1add a0, a0, 1add t3, t3, 1\n它对应的 DAG 图如下，\ngraph TD\n    A0[mul a0, a1, a2]\n    A1[mul a3, a4, a5]\n    A2[add t0, a0, a3]\n    A3[add t0, t2, 1]\n    A4[add t1, t1, 1]\n    A5[add a0, a0, 1]\n    A6[add t3, t3, 1]\n\n    A0 -- RAW --&gt; A2\n    A1 -- RAW --&gt; A2\n    A2 -- WAW --&gt; A3\n    A0 -- RAW --&gt; A5\n显然，刚开始我们有四条就绪指令，即四条入度为 0 的指令，\n=== Ready List ===[mul a0, a1, a2], [mul a3, a4, a5], [add t1, t1, 1], [add t3, t3, 1]\n假设调度器选择mul a0, a1, a2指令进行调度以后，就绪指令会如何变化？\ngraph TD\n    A0[mul a0, a1, a2]\n    A1[mul a3, a4, a5]\n    A2[add t0, a0, a3]\n    A3[add t0, t2, 1]\n    A4[add t1, t1, 1]\n    A5[add a0, a0, 1]\n    A6[add t3, t3, 1]\n\n    A0 ~~~ A2\n    A1 -- RAW --&gt; A2\n    A2 -- WAW --&gt; A3\n    A0 ~~~ A5\nadd a0, a0, 1已经入度为 0，它是否可以直接加入就绪队列，或者什么时候它可以被加入就绪队列？mul a3, a4, a5是否与上一条被调度的指令有结构冲突，它是否需要被剔出就绪队列？\n显然这个问题，我们在没有任何信息的情况下，是无法判断的，因为这是平台相关的信息，是由硬件流水线决定的。所以，我们就需要调度模型来解决这些问题了，我们需要给流水线进行建模，在建立的模型中包含以上信息，提供给调度算法查询，基于这些信息，调度算法才能做出更优的判断。因此，调度器可以认为是调度算法与调度模型共同组成的。如果没有调度模型，调度算法就无法获取流水线信息，只能基于默认的假设值来做调度，那么自然调度的效果就不会太好。\n因此，我们可以这样定义调度模型（Scheduling Model）：调度模型是一组用于抽象目标架构中流水线行为的参数集合，它描述了指令在硬件上的资源需求、延迟特性、执行约束等信息，供调度算法参考与查询，从而生成更符合硬件实际的指令排列方案。\n它通常会回答如下问题：\n\n同一个周期内最多能发射几条指令？\n发射一条指令时，会占用哪些资源？资源是否冲突？\n一条指令的输出什么时候可被下一条使用？\n\n这些信息对顺序核调度尤为关键，因为这些核心无法自动乱序调度、规避冲突，只能依赖静态调度器的来尽可能高效地填满流水线。\nAbout Dispatch Stalls·\n我们首先来回答第一个问题，\n假设我们现在有个 n 发射的流水线，我们先不考虑它的功能单元种类和数量，一个简化的流水线就如下图所示，\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n    Issue2[Slot 2]\n\tIssue..[...]\n    Issuen[Slot n]\n    \n    %% Pipelins\n    EX[EX Stage]\n\t...[...]\n\n    %% Connections\n    Issue0 --&gt; EX\n    Issue1 --&gt; EX\n    Issue2 --&gt; EX\n    Issuen --&gt; EX\n    EX --&gt; ...\n既然这个流水线只有 n 个 Slot 可以使用，那么在同一个周期，它最多只能发射 n 个微操作，如果微操作的数量多于 n 个，则会在发射阶段阻塞，导致前端流水线暂停。\n那么，我们就需要告诉调度器，我们这个流水线有 n 个发射通路。当然，只有发射通路的数量是不够的，我们还需要告诉调度器，每条指令会被解码成多少个微操作。因此，我们需要在struct Pipeline中添加issue_width来表示发射通路数量，并且新创建一个struct Ins，并添加num_micro_ops变量来表示这条指令会被解码成多少个微操作。\nstruct Pipeline &#123;  int issue_width;&#125;;struct Ins &#123;  int num_micro_ops;  &#125;;\n调度器在拿到这两个信息以后，就可以控制在一个周期内发射的指令，让其num_micro_ops的总和不超过issue_width，就可以防止流水线在实际运行中发生发射阻塞了。\n\n当然这里说的是理想情况。真实情况下，由于调度模型可能存在不准确性，无法百分百契合对应硬件流水线，以及调度器中存在复杂的启发式算法，会根据不同情况选择不同的指令进行调度，比如，一个可能导致三个周期停顿的数据依赖和只导致一个周期停顿的发射停顿，调度器理应选择后者优先调度。\n\nAbout Resource Conflicts·\n资源冲突的例子在第一篇举过很多，这里就不再赘述。如果想要调度器能够在调度时候充分考虑到资源冲突的情况，自然需要告诉调度器，流水线有哪些功能单元，对应的功能单元有多少个，以及什么指令使用什么功能单元。\nstruct FuncUnit &#123;  int num_units; &#125;;struct Pipeline &#123;  int issue_width;  struct FuncUnit* func_units[];&#125;;struct Ins &#123;  int num_micro_ops;  struct FuncUnit* used_unit;&#125;;\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n\tIssue1[Slot 1]\n\n    %% Pipelines\n    ALU0[ALU0]\n    ALU1[ALU1]\n    MUL[MUL]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; MUL\n对于上图流水线，我们可以构建对应FuncUnit，Pipeline，Ins，\n// FuncUnit ALUstruct FuncUnit* ALU = malloc(...);// FuncUnit MULstruct FuncUnit* MUL = malloc(...);ALU-&gt;num_units = 2;MUL-&gt;num_units = 1;// Pipeline _Pipelinestruct Pipeline* _Pipeline = malloc(...);_Pipeline-&gt;issue_width = 2;_Pipeline-&gt;func_units[0] = ALU;_Pipeline-&gt;func_units[1] = MUL;// Ins Add and Mulstruct Ins* Add = malloc(...);struct Ins* Mul = malloc(...);Add-&gt;num_micro_ops = 1;Add-&gt;used_unit = ALU;Mul-&gt;num_micro_ops = 1;Mul-&gt;used_unit = MUL;\n\n这里只是为了讲解调度模型里面的内容，就不纠结 c 的语法了～\n\nSo，当调度器拿到这些信息以后，就可以在对汇编调度时考虑到资源冲突了。\n比如当遇到如下汇编，\nadd a0, a0, a1add a2, a3, a2mul t2, t3, t4mul t0, t0, t1\n当处理前两条add时，调度器可以知道，它们的num_micro_ops都为 1，因此双发不会导致发射阻塞，并且它们需要使用ALU单元，并且ALU单元剩余两个也不会发生资源冲突，因此，两条add可以在第一个周期发射。\n第二个周期，在处理两条mul指令时，由于它们的num_micro_ops都为 1，因此双发不会导致发射阻塞，但是它们都需要使用MUL单元，而MUL单元只有一个，因此在同一周期发射会导致资源冲突。\n那么，新的问题来了，何时能发射第二条mul指令呢？\n问题的答案自然很简单，在第一条mul指令释放MUL单元以后，第二条mul指令就能发射了，那么第一条mul指令何时会释放其占据的功能单元呢？\n不知道你是否想到第一篇中所提到的内容，如果一个功能单元是流水线化的，那么它每个周期都能进入一条新的指令，如果它不是流水线化的，那么它可能就会被占据多个周期再释放。\n因此，如果MUL单元是完全流水线化的，那么，第二条mul指令即可以在第三个周期被发射，如果MUL单元是非流水线化的，那么，我们就需要告诉调度器，这个功能单元会被占用多久了。\n最终，一个可以详细描述流水线中的资源使用情况的结构体定义如下所示，\nstruct FuncUnit &#123;  // How many does it have?  int num_units; &#125;;struct Pipeline &#123;  int issue_width;  struct FuncUnit* func_units[];&#125;;struct Ins &#123;  // How many mirco_ops does it have?  int num_micro_ops;  // Which FuncUnit does it take?  struct FuncUnit* used_unit;  // How many cycles does it take?  int taken_cycles;&#125;;\nAbout Data Conflicts·\n所谓数据冲突，自然是体系结构常说的，写后读，读后写，以及写后写，对应数据依赖，反依赖，以及输出依赖。其中反依赖和输出依赖称之为假依赖，可以通过寄存器重命名技术完全消除指令间的这两种依赖关系，而数据依赖是真依赖，是无法消除的。\n\n寄存器重命名技术通常使用在乱序 CPU 中，因此对于乱序 CPU，需要主要关注的是数据依赖。而顺序 CPU 为主要为了节省资源，很少会使用寄存器重命名技术，因此三种依赖关系都是需要考虑在内的。\n\n假设两条存在数据冲突的汇编分别为A和B，如下图所示，它们之间的边Latency = n表示它们需要间隔 n 个周期发射，才能保证流水线正常运行。\ngraph TD\n    A -- Latency = n --&gt; B\n对于反依赖来说，这是一种最简单的依赖关系，因为它只影响调度顺序，即使两条存在反依赖的指令被排布在一起，也不会导致流水线暂停。\naddi a1, a0, 1mul a0, a2, a3\n如上汇编，addi读a0，mul写a0，这构成一条 WAR 反依赖。\n在大多数顺序CPU中，这类依赖并不会引起流水线暂停，因为读取和写回发生在不同的流水线阶段，并且读取阶段通常在写回阶段之前，如下图所示，addi如果和mul一起进入流水线，addi的读取发生在 ID 阶段，而mul的写回发生在 WB 阶段，前者是一定可以读取到正确的a0的值，而后者的写回也不会受到任何前者读取的影响。\nflowchart LR\n    IF[IF]\n    ID[ID]\n    EX[EX]\n    MEM[MEM]\n    WB[WB]\n\n    IF --&gt; ID\n    ID --&gt; EX\n    EX --&gt; MEM\n    MEM --&gt; WB\n因此，我们认为两条存在反依赖的汇编之间的延迟为 0。\ngraph TD\n    A0[addi a1, a0, 1]\n    A1[mul a0, a2, a3]\n\n    A0 -- WAR: Latency = 0 --&gt; A1\n再看稍微复杂一些的输出依赖，如下，addi和mul均写a0寄存器，这构成一条 WAW 输出依赖。\naddi a0, a1, 1mul a0, a2, a3\n对于这两条指令，我们依然可以像分析反依赖一样，假设两条汇编同时进入五级流水线，它们就会同时到达 WB 阶段。由于它们请求写入同一寄存器，而在没有复杂的优先级仲裁的情况下，一个寄存器同一周期只能允许一个值的写入。因此addi会在当前周期成功写入a0值，而mul指令则要等待下一个周期才能写入，因此如果两条存在 WAW 输出依赖的指令同时进入流水线，会发生一个周期的停顿。\n\n这里“没有复杂的优先级仲裁”说的主要也是顺序 CPU，顺序 CPU 的设计一般都会尽可能的降低功耗，节省资源，因此不会引入复杂的硬件机制，因此 WAW 输出依赖通常都会有一个周期的延迟，而乱序核是可以在一个周期发射存在 WAW 输出依赖的汇编指令的。\n\n因此，我们认为两条存在输出依赖的汇编之间的延迟为 1。\ngraph TD\n    A0[addi a0, a1, 1]\n    A1[mul a0, a2, a3]\n\n    A0 -- WAW: Latency = 1 --&gt; A1\n我们前面提到的两种数据依赖关系 —— 反依赖（WAR） 和 输出依赖（WAW） —— 本质上是与具体指令无关的。只要两条写相同寄存器的指令被安排在同一个周期发射，都会触发 WAW 冲突，不管它们是不是 addi 还是 mul。所以这类依赖在顺序核中，我们可以认为它们的延迟是定值，因此无需在调度模型中额外建模。\n但真正复杂的，是 RAW 数据依赖。这种依赖是和具体的指令、甚至是具体的操作数位置绑定在一起的，也就是说，看似相似的 RAW 依赖，所带来的延迟也不尽相同。\n例如我们来看下面这两段汇编：\n---1---addi a0, a1, 1mul a2, a0, a3---2---mul a0, a2, a3addi a1, a0, 1\n它们都存在一个从 a0 读写之间的 RAW 依赖，但情况不一样：\n\n第一组中，mul 依赖的是 addi 的输出，它得等 addi 把结果写完，才能开始执行。\n第二组则是 addi 依赖 mul 的输出，由于 mul 通常比 addi 要慢，这种依赖导致更长的停顿。\n\n所以我们可以总结为，RAW 依赖的关键在于，前一条指令写出来的值，什么时候可以被后续指令读取？这个“什么时候”其实就是一个变量，而这个变量的值显然依赖于前一条指令。\n\n由于现代流水线会存在数据前推（Forwarding），它同样会影响两个汇编序列之间的实际延迟，这点也是需要在调度模型中进行建模的，但是本篇不讨论这个问题，我们将会下一节讨论 LLVM 和 gcc 的调度模型写法时再详述。\n\n为了让调度器能在建 DAG 图的时候考虑这些数据依赖延迟，我们需要在每条指令的调度信息中显式建模它。为此，我们给调度器使用的Ins结构体新增一个变量latency，\nstruct FuncUnit &#123;  int num_units; &#125;;struct Pipeline &#123;  int issue_width;  struct FuncUnit* func_units[];&#125;;struct Ins &#123;  int num_micro_ops;  struct FuncUnit* used_unit;  int taken_cycles;  // How many cycles does its written-reg can be read after it issued.   int latency;&#125;;\n假设addi指令的latency为 1，mul指令的latency为 3，则上述两对汇编构建的 DAG 如下图所示。\ngraph TD\n    A0[addi a0, a1, 1]\n    A1[mul a2, a0, a3]\n\n    A0 -- RAW: Latency = 1 --&gt; A1\n    \n    A2[mul a0, a2, a3]\n    A3[addi a1, a0, 1]\n\n    A2 -- RAW: Latency = 3 --&gt; A3\nSummarize·\n万万没有想到，三个简单的结构体，就基本能把流水线的结构、资源使用和数据依赖描述清楚了。\n对于下面这样一个简单的流水线，\nflowchart LR\n    %% Issue Paths\n    Issue0[Slot 0]\n    Issue1[Slot 1]\n\n    %% Connections\n    Issue0 --&gt; ALU0\n    Issue0 --&gt; ALU1\n    Issue0 --&gt; LDST\n    Issue0 --&gt; FP\n    Issue0 --&gt; MUL\n    Issue0 --&gt; DIV\n我们将指令简单地分为五类，然后用我们定义的结构体来描述一下，\nstruct FuncUnit ALU = &#123; .num_units = 2 &#125;;struct FuncUnit LDST = &#123; .num_units = 1 &#125;;struct FuncUnit FP   = &#123; .num_units = 1 &#125;;struct FuncUnit MUL = &#123; .num_units = 1 &#125;;struct FuncUnit DIV = &#123; .num_units = 1 &#125;;struct Pipeline Simple_Core = &#123;  // 2 slots -- dual-issue pipeline.  .issue_width = 2,  .func_units = &#123; &amp;ALU, &amp;LDST, &amp;FP, &amp;MUL, &amp;DIV &#125;&#125;;struct Ins ALU_ins = &#123;  .num_micro_ops = 1,  .used_unit = &amp;ALU,  .taken_cycles = 1,  .latency = 1&#125;;struct Ins MUL_ins = &#123;  .num_micro_ops = 1,  .used_unit = &amp;MUL,  // assuming MUL is pipelined.  .taken_cycles = 1,  .latency = 3&#125;;struct Ins DIV_ins = &#123;  .num_micro_ops = 1,  .used_unit = &amp;DIV,  // assuming DIV is not-pipelined.  .taken_cycles = 12,  .latency = 12&#125;;struct Ins FP_ins = &#123;  .num_micro_ops = 1,  .used_unit = &amp;FP,  // assuming FP is not-pipelined.  .taken_cycles = 5,  .latency = 5&#125;;\n下一篇我们将讲解 LLVM 和 GCC 中究竟是如何描述一个调度模型的，并且看一下与我在本节定义的结构体分别有哪些对应关系。\nPeace~ ✌️\n","tags":["instruction scheduling"]}]